# 备份页面卡片显示逻辑说明

## 1. 批次触发逻辑

### 配置参数
- **文件数阈值**：`SCAN_BATCH_SIZE`（默认：30000个文件）
- **字节数阈值**：`SCAN_BATCH_SIZE_BYTES`（默认：6GB = 6 * 1024 * 1024 * 1024）

### 触发条件
```python
should_compress = (
    len(current_batch) >= batch_size_files OR  # 文件数达到阈值
    current_batch_size >= batch_size_bytes     # 字节数达到阈值
)
```
**说明**：只要满足**任一条件**就会触发压缩，不是两个条件都要满足。

### 日志示例
```
批次配置：文件数阈值=30000, 字节数阈值=6.00 GB
已扫描 100 个文件，找到 99 个有效文件...
达到批次阈值，开始压缩：文件数=100, 大小=15.29 GB
```
**分析**：虽然文件数只有100个（远小于30000），但字节数15.29 GB超过了6.00 GB阈值，所以触发了压缩。

## 2. 卡片显示字段说明

### 2.1 压缩包进度
**显示格式**：`压缩包进度: X/Y`
- **X（已打包文件数）**：`task.total_files` = 已生成的压缩包数量（`group_idx + 1`）
- **Y（预计打包总数）**：`task.estimated_archive_count` = 预计的压缩包总数（估算值）
- **数据来源**：`/api/backup/tasks/{id}/status` 接口返回的 `total_files` 和 `estimated_archive_count`

### 2.2 文件进度
**显示格式**：`文件进度: X/Y`
- **X（已处理文件）**：`task.processed_files` = 已处理文件数（累计处理的所有文件数）
- **Y（批次相加的文件数）**：`task.total_bytes` = 所有扫描到的文件总数（所有批次扫描到的文件数累计）
- **数据来源**：`/api/backup/tasks/{id}/status` 接口返回的 `processed_files` 和 `total_bytes`

### 2.3 压缩率
**显示格式**：`压缩率: X.X%`
- **计算公式**：`compression_ratio = compressed_bytes / processed_bytes`
  - `compressed_bytes`：压缩后的总大小（所有压缩包的总大小）
  - `processed_bytes`：原始文件的总大小（未压缩）
- **显示条件**：仅在 `compressed_bytes > 0 && compression_ratio > 0` 时显示
- **数据来源**：优先使用API返回的 `compression_ratio`，否则根据 `compressed_bytes` 和 `processed_bytes` 计算

### 2.4 进度百分比
**显示格式**：`进度: X.X%`
- **数据来源**：`task.progress_percent`（0-100）
- **计算逻辑**：扫描阶段占10%，压缩阶段占90%

### 2.5 源路径和目标
- **源路径**：`task.source_paths`（数组，多个路径用逗号分隔）
- **目标**：`task.tape_device` 或 `task.tape_id` 或 "自动选择"

## 3. 后端数据更新逻辑

### 3.1 字段更新时机
- **`processed_files`**：每处理完一个文件组后累加 `len(file_group)`
- **`total_files`**：每生成一个压缩包后更新为 `group_idx + 1`
- **`total_bytes`**：每扫描完一个批次后累加 `len(file_batch)`
- **`processed_bytes`**：每处理完一个文件组后累加 `total_original_size`
- **`compressed_bytes`**：每处理完一个文件组后累加 `total_size`
- **`estimated_archive_count`**：根据已扫描的文件数和平均文件大小估算，存储在 `result_summary` JSON字段中

### 3.2 数据存储位置
- **数据库表**：`backup_tasks`
- **字段映射**：
  - `processed_files` → `processed_files`（INTEGER）
  - `total_files` → `total_files`（INTEGER，表示压缩包数量）
  - `total_bytes` → `total_bytes`（INTEGER，表示扫描到的文件总数）
  - `processed_bytes` → `processed_bytes`（BIGINT，原始文件总大小）
  - `compressed_bytes` → `compressed_bytes`（BIGINT，压缩后总大小）
  - `estimated_archive_count` → `result_summary`（JSON字段）

## 4. 前端更新逻辑

### 4.1 卡片创建
- 位置：`loadRunningTasks()` 函数
- 时机：检测到新任务时创建卡片
- HTML结构：见 `web/templates/backup.html` 第739-802行

### 4.2 卡片更新
- 位置：`loadRunningTasks()` 函数中的更新逻辑
- 时机：每2秒轮询一次 `/api/backup/tasks/{id}/status`
- 更新字段：
  1. 状态徽章（运行中/格式化中/失败）
  2. 操作状态（扫描中/压缩中/写入中）
  3. 进度百分比和进度条
  4. 压缩包进度（`total_files / estimated_archive_count`）
  5. 文件进度（`processed_files / total_bytes`）
  6. 压缩率（`compressed_bytes / processed_bytes`）
  7. 源路径和目标路径

### 4.3 数据获取
- **主要接口**：`GET /api/backup/tasks/{id}/status`
- **返回字段**：
  ```json
  {
    "task_id": 123,
    "status": "running",
    "progress_percent": 45.5,
    "processed_files": 500,
    "total_files": 3,
    "total_bytes": 1000,
    "processed_bytes": 10737418240,
    "compressed_bytes": 5368709120,
    "compression_ratio": 0.5,
    "estimated_archive_count": 10,
    "description": "[压缩文件中...]",
    "source_paths": ["D:\\", "E:\\"],
    "tape_device": "\\\\.\\scsi0",
    "tape_id": "TP20251101"
  }
  ```

## 5. 配置问题修复

### 5.1 settings.py 注释修正
- `SCAN_BATCH_SIZE`：注释应改为"默认30000个文件"（不是3000）
- `SCAN_BATCH_SIZE_BYTES`：注释应改为"默认6GB"（不是3GB）

### 5.2 批次触发日志改进
- 明确显示是哪个阈值触发的（文件数或字节数）
- 格式：`达到批次阈值（字节数），开始压缩：文件数=100, 大小=15.29 GB`

### 5.3 压缩级别配置
- `settings.py` 默认值：`COMPRESSION_LEVEL = 9`
- `.env` 文件覆盖：`COMPRESSION_LEVEL=3`
- 实际使用：`.env` 文件的值（3）

