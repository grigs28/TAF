# 计划任务运行逻辑和流程分析

## 概述

本文档详细分析计划任务（Scheduled Task）从开始执行到完成的全流程，包括调度器循环、任务执行器、动作处理器和备份引擎的完整执行链路。

## 整体架构

```
TaskScheduler (调度器)
    ↓
_scheduler_loop() (调度循环)
    ↓
create_task_executor() (创建执行器)
    ↓
executor() (任务执行函数)
    ↓
get_action_handler() (获取动作处理器)
    ↓
BackupActionHandler.execute() (备份动作处理)
    ↓
BackupEngine.execute_backup_task() (备份引擎执行)
```

## 详细执行流程

### 阶段1: 调度器循环检测

**位置**: `utils/scheduler/scheduler.py` - `TaskScheduler._scheduler_loop()`

**执行逻辑**:

```521:555:utils/scheduler/scheduler.py
    async def _scheduler_loop(self):
        """调度器主循环"""
        while self.running:
            try:
                current_time = datetime.now()
                
                # 检查每个任务
                for task_id, task_info in list(self.tasks.items()):
                    if current_time >= task_info['next_run']:
                        # 执行任务（在后台执行，不阻塞）
                        execution_task = asyncio.create_task(task_info['execute_func']())
                        self._running_executions[task_id] = execution_task
                        
                        # 清理已完成的任务
                        def cleanup_task(exec_task, tid):
                            async def cleanup():
                                try:
                                    await exec_task
                                except Exception:
                                    pass
                                finally:
                                    if tid in self._running_executions:
                                        del self._running_executions[tid]
                            return cleanup
                        
                        asyncio.create_task(cleanup_task(execution_task, task_id)())
                
                # 每分钟检查一次
                await asyncio.sleep(60)
```

**关键点**:
- 每分钟检查一次所有任务
- 当 `current_time >= next_run` 时触发执行
- 使用 `asyncio.create_task()` 在后台异步执行，不阻塞调度循环
- 执行任务存储在 `_running_executions` 字典中，用于跟踪运行状态

### 阶段2: 任务执行器初始化

**位置**: `utils/scheduler/task_executor.py` - `create_task_executor()`

**执行逻辑**:

```27:90:utils/scheduler/task_executor.py
def create_task_executor(scheduled_task: ScheduledTask, system_instance, manual_run: bool = False) -> Callable:
    """创建任务执行函数
    
    Args:
        scheduled_task: 计划任务对象
        system_instance: 系统实例
        manual_run: 是否为手动运行（Web界面点击运行），默认为False
    """
    async def executor():
        execution_id = str(uuid.uuid4())
        start_time = datetime.now()
        lock_acquired = False
        
        try:
            # 获取任务并发锁（openGauss原生），获取失败则跳过
            got_lock = await acquire_task_lock(scheduled_task.id, execution_id)
            if not got_lock:
                await log_system(
                    level=LogLevel.INFO,
                    category=LogCategory.SCHEDULER,
                    message="任务已在执行中，跳过",
                    module="scheduler",
                    function="task_executor",
                    task_id=scheduled_task.id,
                    details={"execution_id": execution_id}
                )
                return
            
            lock_acquired = True

            # 记录任务执行开始日志
            await log_operation(
                operation_type=OperationType.SCHEDULER_RUN,
                resource_type="scheduler",
                resource_id=str(scheduled_task.id),
                resource_name=scheduled_task.task_name,
                operation_name="执行计划任务",
                operation_description=f"开始执行计划任务: {scheduled_task.task_name}",
                category="scheduler",
                success=True,
                result_message=f"任务执行开始 (执行ID: {execution_id})"
            )
            
            # 更新任务状态为运行中（openGauss使用原生SQL，其他使用SQLAlchemy）
            if is_opengauss():
                conn = await get_opengauss_connection()
                try:
                    await conn.execute(
                        """
                        UPDATE scheduled_tasks
                        SET status = $1::scheduledtaskstatus, last_run_time = $2
                        WHERE id = $3
                        """,
                        'running', start_time, scheduled_task.id
                    )
                finally:
                    await conn.close()
            else:
                async with db_manager.AsyncSessionLocal() as session:
                    scheduled_task.status = ScheduledTaskStatus.RUNNING
                    scheduled_task.last_run_time = start_time
                    session.add(scheduled_task)
                    await session.commit()
```

**关键点**:
- 生成唯一的 `execution_id` 用于跟踪本次执行
- 使用数据库锁机制防止并发执行（`acquire_task_lock`）
- 更新任务状态为 `RUNNING`
- 记录执行开始日志

### 阶段3: 动作处理器执行前检查

**位置**: `utils/scheduler/action_handlers.py` - `BackupActionHandler.execute()`

#### 3.1 周期检查（仅自动运行）

```58:103:utils/scheduler/action_handlers.py
            # 执行前判定：周期内是否已成功执行、是否正在执行、磁带标签是否当月
            current_time = now()
            if scheduled_task and not manual_run:
                # 1) 周期检查（按任务的 schedule_type 推断周期：日/周/月/年）
                # 注意：手动运行时跳过周期检查
                cycle_ok = True
                last_success = scheduled_task.last_success_time
                schedule_type = getattr(scheduled_task, 'schedule_type', None)
                if last_success:
                    if schedule_type and getattr(schedule_type, 'value', '').lower() in ('daily', 'day'):
                        cycle_ok = (last_success.date() != current_time.date())
                    elif schedule_type and getattr(schedule_type, 'value', '').lower() in ('weekly', 'week'):
                        cycle_ok = (last_success.isocalendar().week != current_time.isocalendar().week or last_success.year != current_time.year)
                    elif schedule_type and getattr(schedule_type, 'value', '').lower() in ('monthly', 'month'):
                        cycle_ok = (last_success.year != current_time.year or last_success.month != current_time.month)
                    elif schedule_type and getattr(schedule_type, 'value', '').lower() in ('yearly', 'year'):
                        cycle_ok = (last_success.year != current_time.year)
                    else:
                        # 未明确类型，默认按日
                        cycle_ok = (last_success.date() != current_time.date())
                # 如果周期内已执行过，则跳过
                if not cycle_ok:
                    logger.info("当前周期内已成功执行，跳过本次备份")
                    try:
                        await log_operation(
                            operation_type=OperationType.SCHEDULER_RUN,
                            resource_type="scheduler",
                            resource_id=str(getattr(scheduled_task, 'id', '')),
                            resource_name=getattr(scheduled_task, 'task_name', ''),
                            operation_name="执行计划任务",
                            operation_description="跳过：当前周期已执行",
                            category="scheduler",
                            success=True,
                            result_message="跳过执行（当前周期已执行）"
                        )
                        await log_system(
                            level=LogLevel.INFO,
                            category=LogCategory.SCHEDULER,
                            message="计划任务跳过：当前周期已执行",
                            module="utils.scheduler.action_handlers",
                            function="BackupActionHandler.execute",
                            task_id=getattr(scheduled_task, 'id', None)
                        )
                    except Exception:
                        pass
                    return {"status": "skipped", "message": "当前周期已执行"}
            elif manual_run:
                logger.info("手动运行模式，跳过周期检查")
```

**检查逻辑**:
- **Daily**: 检查日期是否相同
- **Weekly**: 检查周数和年份是否相同
- **Monthly**: 检查月份和年份是否相同
- **Yearly**: 检查年份是否相同
- 如果周期内已执行，返回 `{"status": "skipped"}` 并跳过

#### 3.2 运行中检查

```107:132:utils/scheduler/action_handlers.py
            # 2) 运行中检查（根据任务状态）- 手动运行和自动运行都检查
            if scheduled_task and getattr(scheduled_task, 'status', None) and str(scheduled_task.status).upper().endswith('RUNNING'):
                logger.info("任务仍在执行中，跳过本次备份")
                try:
                    await log_operation(
                        operation_type=OperationType.SCHEDULER_RUN,
                        resource_type="scheduler",
                        resource_id=str(getattr(scheduled_task, 'id', '')),
                        resource_name=getattr(scheduled_task, 'task_name', ''),
                        operation_name="执行计划任务",
                        operation_description="跳过：任务正在执行中",
                        category="scheduler",
                        success=True,
                        result_message="跳过执行（任务正在执行中）"
                    )
                    await log_system(
                        level=LogLevel.INFO,
                        category=LogCategory.SCHEDULER,
                        message="计划任务跳过：任务正在执行中",
                        module="utils.scheduler.action_handlers",
                        function="BackupActionHandler.execute",
                        task_id=getattr(scheduled_task, 'id', None)
                    )
                except Exception:
                    pass
                return {"status": "skipped", "message": "任务正在执行中"}
```

**检查逻辑**:
- 检查任务状态是否为 `RUNNING`
- 如果正在运行，跳过本次执行

#### 3.3 磁带标签当月验证

```134:203:utils/scheduler/action_handlers.py
            # 3) 磁带标签是否当月（从 LTFS 标签或磁带头读取）
            # 仅当备份目标为磁带时要求当月
            # 注意：手动运行和自动运行都检查磁带标签
            if scheduled_task:
                target_is_tape = False
                try:
                    # 从 scheduled_task.action_config 读取备份目标
                    action_cfg = scheduled_task.action_config or {}
                    target_is_tape = (action_cfg.get('backup_target') == 'tape') or ('tape_device' in action_cfg)
                except Exception:
                    pass
                if target_is_tape and self.system_instance and getattr(self.system_instance, 'tape_manager', None):
                    tape_ops = getattr(self.system_instance.tape_manager, 'tape_operations', None)
                    if tape_ops and hasattr(tape_ops, '_read_tape_label'):
                        metadata = await tape_ops._read_tape_label()
                        # 无标签时允许继续，后续会自动提示换盘逻辑在业务层处理
                        if metadata and (metadata.get('created_date') or metadata.get('tape_id')):
                            try:
                                # 优先使用 created_date
                                created_dt = None
                                if metadata.get('created_date'):
                                    try:
                                        created_dt = datetime.fromisoformat(str(metadata['created_date']).replace('Z','+00:00'))
                                    except Exception:
                                        created_dt = None
                                if created_dt:
                                    if not (created_dt.year == current_time.year and created_dt.month == current_time.month):
                                        raise ValueError("当前磁带非当月，请更换磁带后重试")
                                else:
                                    # 备用：从 tape_id 推断（如 TAPyymmddxxx）
                                    tape_id = str(metadata.get('tape_id', ''))
                                    if len(tape_id) >= 7 and tape_id.upper().startswith('TAP'):
                                        yy = int(tape_id[3:5])
                                        mm = int(tape_id[5:7])
                                        year = 2000 + yy
                                        if not (year == current_time.year and mm == current_time.month):
                                            raise ValueError("当前磁带标签非当月，请更换磁带后重试")
                            except ValueError as ve:
                                # 记录并抛出以触发通知与日志
                                logger.warning(str(ve))
                                # 通知：需要更换磁带
                                try:
                                    if self.system_instance and getattr(self.system_instance, 'dingtalk_notifier', None):
                                        notifier = self.system_instance.dingtalk_notifier
                                        tape_id = (metadata.get('tape_id') if metadata else '') or '未知磁带'
                                        await notifier.send_tape_notification(tape_id=tape_id, action='change_required')
                                except Exception:
                                    pass
                                # 记录日志
                                try:
                                    await log_operation(
                                        operation_type=OperationType.BACKUP_START,
                                        resource_type="backup",
                                        resource_name=(getattr(scheduled_task, 'task_name', '') or '计划任务'),
                                        operation_name="更换磁带提醒",
                                        operation_description="当前磁带标签非当月，提醒更换磁带",
                                        category="backup",
                                        success=False,
                                        error_message=str(ve)
                                    )
                                    await log_system(
                                        level=LogLevel.WARNING,
                                        category=LogCategory.BACKUP,
                                        message="当前磁带标签非当月，提醒更换磁带",
                                        module="utils.scheduler.action_handlers",
                                        function="BackupActionHandler.execute",
                                    )
                                except Exception:
                                    pass
                                raise
```

**检查逻辑**:
- 仅当备份目标为磁带时检查
- 读取磁带卷标，验证年月是否匹配当前年月
- 如果不匹配，发送钉钉通知要求更换磁带，并抛出异常

### 阶段4: 创建备份任务执行记录

**位置**: `utils/scheduler/action_handlers.py` - `BackupActionHandler.execute()`

```393:467:utils/scheduler/action_handlers.py
            # 创建备份任务执行记录（不是模板）
            if is_opengauss():
                # openGauss 原生SQL插入
                conn = await get_opengauss_connection()
                try:
                    backup_task_id = await conn.fetchval(
                        """
                        INSERT INTO backup_tasks (
                            task_name, task_type, source_paths, exclude_patterns,
                            compression_enabled, encryption_enabled, retention_days,
                            description, tape_device, status, is_template, template_id,
                            created_by, created_at, updated_at
                        ) VALUES (
                            $1, $2::backuptasktype, $3, $4,
                            $5, $6, $7,
                            $8, $9, $10::backuptaskstatus, FALSE, $11,
                            $12, $13, $13
                        ) RETURNING id
                        """,
                        task_name,
                        task_type.value if hasattr(task_type, 'value') else str(task_type),
                        json.dumps(source_paths) if source_paths else None,
                        json.dumps(exclude_patterns) if exclude_patterns else None,
                        compression_enabled,
                        encryption_enabled,
                        retention_days,
                        description,
                        tape_device,
                        'pending',
                        template_task.id if template_task else None,
                        'scheduled_task',
                        now()
                    )
                    
                    # 创建一个简化的 BackupTask 对象用于后续使用
                    backup_task = type('BackupTask', (), {
                        'id': backup_task_id,
                        'task_name': task_name,
                        'task_type': task_type,
                        'source_paths': source_paths,
                        'exclude_patterns': exclude_patterns,
                        'compression_enabled': compression_enabled,
                        'encryption_enabled': encryption_enabled,
                        'retention_days': retention_days,
                        'description': description,
                        'tape_device': tape_device,
                        'status': BackupTaskStatus.PENDING,
                        'is_template': False,
                        'template_id': template_task.id if template_task else None,
                        'created_by': 'scheduled_task',
                    })()
                finally:
                    await conn.close()
            else:
                # 使用SQLAlchemy插入
                async with db_manager.AsyncSessionLocal() as session:
                    backup_task = BackupTask(
                        task_name=task_name,
                        task_type=task_type,
                        source_paths=source_paths,
                        exclude_patterns=exclude_patterns,
                        compression_enabled=compression_enabled,
                        encryption_enabled=encryption_enabled,
                        retention_days=retention_days,
                        description=description,
                        tape_device=tape_device,  # 保存磁带设备配置（执行时会选择）
                        status=BackupTaskStatus.PENDING,
                        is_template=False,  # 标记为执行记录
                        template_id=template_task.id if template_task else None,  # 关联模板
                        created_by='scheduled_task'
                    )
                    
                    session.add(backup_task)
                    await session.commit()
                    await session.refresh(backup_task)
```

**关键点**:
- 从模板或配置加载备份参数
- 创建 `backup_tasks` 表记录，`is_template=False` 表示这是执行记录
- 设置任务状态为 `PENDING`
- 关联模板ID（`template_id`）

### 阶段5: 完整备份前格式化（FULL类型任务）

**位置**: `utils/scheduler/action_handlers.py` - `BackupActionHandler.execute()`

```469:501:utils/scheduler/action_handlers.py
            # 完整备份前：格式化磁带（计划任务使用当前年月生成卷标）
            if (template_task and template_task.task_type == BackupTaskType.FULL) or (not template_task and task_type == BackupTaskType.FULL):
                try:
                    await log_system(
                        level=LogLevel.INFO,
                        category=LogCategory.BACKUP,
                        message="开始完整备份前格式化（使用当前年月）",
                        module="utils.scheduler.action_handlers",
                        function="BackupActionHandler.execute",
                    )
                    if self.system_instance and getattr(self.system_instance, 'tape_manager', None):
                        tape_ops = getattr(self.system_instance.tape_manager, 'tape_operations', None)
                        if tape_ops and hasattr(tape_ops, 'erase_preserve_label'):
                            # 计划任务格式化时使用当前年月生成卷标
                            ok = await tape_ops.erase_preserve_label(use_current_year_month=True)
                            if not ok:
                                logger.warning("完整备份前格式化失败，将尝试继续执行备份")
                                await log_system(
                                    level=LogLevel.WARNING,
                                    category=LogCategory.BACKUP,
                                    message="完整备份前格式化失败，继续执行",
                                    module="utils.scheduler.action_handlers",
                                    function="BackupActionHandler.execute",
                                )
                except Exception as _:
                    logger.warning("完整备份前格式化异常，将尝试继续执行备份")
                    await log_system(
                        level=LogLevel.WARNING,
                        category=LogCategory.BACKUP,
                        message="完整备份前格式化异常，继续执行",
                        module="utils.scheduler.action_handlers",
                        function="BackupActionHandler.execute",
                    )
```

**关键点**:
- 仅当任务类型为 `FULL` 时执行格式化
- 使用 `erase_preserve_label(use_current_year_month=True)` 格式化
- 格式化失败不会阻止备份任务执行，只记录警告

**格式化详细流程**（参考 `docs/scheduled_task_execution_details.md`）:
1. 格式化前记录原卷标
2. 生成新卷标（格式：`TP{YYYY}{MM}01`，例如：`TP20251101`）
3. 执行 `LtfsCmdFormat.exe` 命令
4. 格式化成功后读取新卷标
5. 更新数据库：使用原卷标查找记录，更新为新卷标

### 阶段6: 执行备份任务

**位置**: `utils/scheduler/action_handlers.py` - `BackupActionHandler.execute()`

```503:527:utils/scheduler/action_handlers.py
            # 执行备份任务
            await log_system(
                level=LogLevel.INFO,
                category=LogCategory.BACKUP,
                message="开始执行备份任务",
                module="utils.scheduler.action_handlers",
                function="BackupActionHandler.execute",
                details={"backup_task_id": getattr(backup_task, 'id', None), "task_name": task_name}
            )
            # 执行备份任务（传入 scheduled_task 和 manual_run 以便进行执行前检查）
            logger.info(f"调用备份引擎执行备份任务... (手动运行: {manual_run})")
            success = await self.system_instance.backup_engine.execute_backup_task(backup_task, scheduled_task=scheduled_task, manual_run=manual_run)
            logger.info(f"备份任务执行完成，结果: {'成功' if success else '失败'}")
            await log_system(
                level=LogLevel.INFO if success else LogLevel.ERROR,
                category=LogCategory.BACKUP,
                message="备份任务执行结束" + ("(成功)" if success else "(失败)"),
                module="utils.scheduler.action_handlers",
                function="BackupActionHandler.execute",
                details={
                    "backup_task_id": getattr(backup_task, 'id', None),
                    "total_bytes": getattr(backup_task, 'total_bytes', None),
                    "total_files": getattr(backup_task, 'total_files', None),
                }
            )
```

**关键点**:
- 调用 `BackupEngine.execute_backup_task()` 执行备份
- 传入 `scheduled_task` 和 `manual_run` 参数
- 备份引擎内部会再次检查格式化（如果任务类型为FULL）

### 阶段7: 备份引擎执行流程

**位置**: `backup/backup_engine.py` - `BackupEngine.execute_backup_task()`

#### 7.1 备份引擎执行前检查

备份引擎内部会进行以下检查：

1. **任务执行状态检查**（仅自动执行时）
   - 检查相同模板的任务是否在存活期内已成功执行

2. **任务运行状态检查**
   - 检查任务是否正在执行中

3. **磁带卷标当月验证**
   - 再次验证磁带卷标是否匹配当前年月

4. **完整备份前格式化**（如果任务类型为FULL）
   - 备份引擎也会执行格式化（保留原卷标）
   - 注意：计划任务已经在动作处理器中执行过格式化（使用当前年月）

#### 7.2 备份执行流程

备份引擎执行的主要步骤：

1. **扫描文件**
   - 扫描源路径下的所有文件
   - 计算总文件数和总字节数

2. **压缩和写入**
   - 压缩文件（如果启用）
   - 写入到磁带设备

3. **进度更新**
   - 实时更新 `processed_files` 和 `processed_bytes`
   - 计算 `progress_percent`

4. **完成处理**
   - 更新任务状态为 `COMPLETED`
   - 记录完成时间和统计信息

### 阶段8: 任务完成处理

**位置**: `utils/scheduler/task_executor.py` - `executor()`

#### 8.1 成功处理

```145:332:utils/scheduler/task_executor.py
            end_time = datetime.now()
            duration = int((end_time - start_time).total_seconds() * 1000)  # 转换为毫秒
            
            # 更新执行日志和任务统计（openGauss使用原生SQL，其他使用SQLAlchemy）
            if is_opengauss():
                # openGauss 原生记录结束（成功）
                try:
                    await record_run_end(execution_id, end_time, 'success', result=result)
                except Exception:
                    pass
                
                # 更新任务统计（使用原生SQL）
                conn = await get_opengauss_connection()
                try:
                    # 获取当前统计值
                    current_task = await conn.fetchrow(
                        """
                        SELECT total_runs, success_runs, average_duration
                        FROM scheduled_tasks
                        WHERE id = $1
                        """,
                        scheduled_task.id
                    )
                    
                    total_runs = (current_task['total_runs'] or 0) + 1
                    success_runs = (current_task['success_runs'] or 0) + 1
                    
                    # 计算平均执行时长
                    avg_duration = duration // 1000  # 秒
                    if current_task['average_duration']:
                        avg_duration = int((current_task['average_duration'] + avg_duration) / 2)
                    
                    # 计算下次执行时间
                    next_run = calculate_next_run_time(scheduled_task)
                    
                    # 更新任务
                    await conn.execute(
                        """
                        UPDATE scheduled_tasks
                        SET status = $1::scheduledtaskstatus,
                            last_success_time = $2,
                            total_runs = $3,
                            success_runs = $4,
                            average_duration = $5,
                            next_run_time = $6
                        WHERE id = $7
                        """,
                        'active', end_time, total_runs, success_runs, avg_duration, next_run, scheduled_task.id
                    )
                finally:
                    await conn.close()
```

**更新内容**:
- 更新执行日志状态为 `success`
- 更新任务统计：`total_runs`、`success_runs`、`average_duration`
- 更新 `last_success_time`
- 计算并更新 `next_run_time`
- 更新任务状态为 `ACTIVE`

#### 8.2 失败处理

```365:524:utils/scheduler/task_executor.py
        except Exception as e:
            end_time = datetime.now()
            duration = int((end_time - start_time).total_seconds() * 1000)  # 转换为毫秒
            error_msg = str(e)
            import traceback
            stack_trace = traceback.format_exc()
            
            # 详细的任务执行失败日志输出
            duration_seconds = duration / 1000.0
            logger.error("=" * 80)
            logger.error(f"❌ 计划任务执行失败")
            logger.error(f"   任务名称: {scheduled_task.task_name}")
            logger.error(f"   任务ID: {scheduled_task.id}")
            logger.error(f"   执行ID: {execution_id}")
            logger.error(f"   动作类型: {scheduled_task.action_type.value if scheduled_task.action_type else 'N/A'}")
            logger.error(f"   开始时间: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
            logger.error(f"   结束时间: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
            logger.error(f"   执行耗时: {duration_seconds:.2f}秒 ({duration}毫秒)")
            logger.error(f"   错误类型: {type(e).__name__}")
            logger.error(f"   错误消息: {error_msg}")
            logger.error(f"   异常堆栈:")
            for line in stack_trace.split('\n'):
                if line.strip():
                    logger.error(f"     {line}")
            
            # 更新执行日志和任务统计（openGauss使用原生SQL，其他使用SQLAlchemy）
            if is_opengauss():
                # openGauss 原生记录结束（失败）
                try:
                    await record_run_end(execution_id, end_time, 'failed', result=None, error_message=error_msg)
                except Exception:
                    pass
                
                # 更新任务统计（使用原生SQL）
                try:
                    conn = await get_opengauss_connection()
                    try:
                        # 获取当前统计值
                        current_task = await conn.fetchrow(
                            """
                            SELECT total_runs, failure_runs
                            FROM scheduled_tasks
                            WHERE id = $1
                            """,
                            scheduled_task.id
                        )
                        
                        total_runs = (current_task['total_runs'] or 0) + 1
                        failure_runs = (current_task['failure_runs'] or 0) + 1
                        
                        # 更新任务
                        await conn.execute(
                            """
                            UPDATE scheduled_tasks
                            SET status = $1::scheduledtaskstatus,
                                total_runs = $2,
                                failure_runs = $3,
                                last_failure_time = $4,
                                last_error = $5
                            WHERE id = $6
                            """,
                            'error', total_runs, failure_runs, end_time, error_msg, scheduled_task.id
                        )
                    finally:
                        await conn.close()
                except Exception as db_error:
                    logger.error(f"更新任务日志失败: {str(db_error)}")
```

**更新内容**:
- 更新执行日志状态为 `failed`，记录错误信息
- 更新任务统计：`total_runs`、`failure_runs`
- 更新 `last_failure_time` 和 `last_error`
- 更新任务状态为 `ERROR`

#### 8.3 锁释放

```526:536:utils/scheduler/task_executor.py
        finally:
            # 确保无论成功还是失败，都释放任务锁
            # 这个 finally 块会在所有退出路径（return、raise、正常结束）之前执行
            if lock_acquired:
                try:
                    await release_task_lock(scheduled_task.id, execution_id)
                    logger.debug(f"任务锁已释放: {scheduled_task.task_name} (执行ID: {execution_id})")
                except Exception as lock_error:
                    # 即使释放锁失败，也要记录错误，但不影响其他流程
                    logger.error(f"释放任务锁失败: {scheduled_task.task_name} (执行ID: {execution_id}), 错误: {str(lock_error)}")
                    # 注意：即使释放锁失败，我们也不应该重新抛出异常，因为这会掩盖原始错误
```

**关键点**:
- 使用 `finally` 块确保锁一定被释放
- 即使发生异常，也会释放锁

## 执行流程图

```
┌─────────────────────────────────────────────────────────────┐
│ 调度器循环 (_scheduler_loop)                                │
│ - 每分钟检查一次                                            │
│ - 当 current_time >= next_run 时触发                       │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│ 创建任务执行器 (create_task_executor)                       │
│ - 生成 execution_id                                        │
│ - 获取任务锁 (acquire_task_lock)                           │
│ - 更新状态为 RUNNING                                        │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│ 动作处理器执行前检查 (BackupActionHandler.execute)          │
│ ├─ 周期检查（仅自动运行）                                   │
│ ├─ 运行中检查                                               │
│ └─ 磁带标签当月验证                                         │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│ 创建备份任务执行记录                                         │
│ - 从模板加载配置                                            │
│ - 创建 backup_tasks 记录 (is_template=False)                │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│ 完整备份前格式化（FULL类型）                                 │
│ - erase_preserve_label(use_current_year_month=True)         │
│ - 生成卷标: TP{YYYY}{MM}01                                  │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│ 执行备份任务 (BackupEngine.execute_backup_task)             │
│ ├─ 扫描文件                                                 │
│ ├─ 压缩和写入                                                │
│ └─ 更新进度                                                 │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│ 任务完成处理                                                 │
│ ├─ 成功: 更新统计、计算下次执行时间                          │
│ ├─ 失败: 记录错误、更新失败统计                              │
│ └─ 释放任务锁 (release_task_lock)                           │
└─────────────────────────────────────────────────────────────┘
```

## 关键机制说明

### 1. 并发控制

- **数据库锁**: 使用 `acquire_task_lock()` 和 `release_task_lock()` 防止同一任务并发执行
- **状态检查**: 检查任务状态是否为 `RUNNING`，如果正在运行则跳过

### 2. 周期控制

- **周期检查**: 根据 `schedule_type` 判断周期（日/周/月/年）
- **手动运行**: 手动运行时跳过周期检查，允许立即执行

### 3. 磁带管理

- **卷标验证**: 验证磁带卷标是否匹配当前年月
- **格式化**: FULL类型任务执行前格式化，使用当前年月生成卷标

### 4. 错误处理

- **格式化失败**: 格式化失败不会阻止备份任务执行，只记录警告
- **备份失败**: 备份失败会更新任务状态为 `ERROR`，记录错误信息
- **锁释放**: 使用 `finally` 块确保锁一定被释放

### 5. 日志记录

- **操作日志**: 记录任务执行的开始、成功、失败等关键操作
- **系统日志**: 记录详细的执行信息，包括执行ID、耗时、结果等
- **错误日志**: 记录异常堆栈和错误详情

## 压缩配置分析

### 7z多线程压缩配置状态

#### 配置项说明

**位置**: `config/settings.py`

```118:118:config/settings.py
    COMPRESSION_THREADS: int = 4
```

系统配置中定义了 `COMPRESSION_THREADS: int = 4`，用于指定压缩时使用的线程数。

#### 实际使用情况

**当前状态**: **7z（py7zr）多线程压缩未启用**

**原因分析**:

1. **配置存在但未使用**
   - `COMPRESSION_THREADS` 配置项存在于 `config/settings.py` 中
   - 但在实际压缩代码中未被引用

2. **实际使用的是 tar.gz 压缩**
   - 备份引擎使用 Python 标准库的 `tarfile` 模块进行压缩
   - 压缩格式为 `tar.gz`（gzip压缩），而非 7z 格式

3. **代码实现位置**

```1429:1461:backup/backup_engine.py
    async def _compress_file_group(self, file_group: List[Dict], backup_set: BackupSet, backup_task: BackupTask,
                                   base_processed_files: int = 0, total_files: int = 0) -> Optional[Dict]:
        """压缩文件组（简单的tar备份，带进度跟踪）"""
        try:
            import tarfile
            import threading
            import time
            
            # 从备份任务获取压缩设置
            compression_enabled = getattr(backup_task, 'compression_enabled', True)
            
            # 从系统配置获取压缩级别
            compression_level = self.settings.COMPRESSION_LEVEL
            
            # 创建临时文件（直接写入磁带盘符，不创建临时文件）
            timestamp = format_datetime(now(), '%Y%m%d_%H%M%S')
            tape_drive = self.settings.TAPE_DRIVE_LETTER.upper() + ":\\"
            backup_dir = Path(tape_drive) / backup_set.set_id
            backup_dir.mkdir(parents=True, exist_ok=True)
            
            # 进度跟踪变量
            tar_progress = {'bytes_written': 0, 'running': True}
            total_original_size = sum(f['size'] for f in file_group)
            
            # 将tar操作放到线程池中执行，避免阻塞事件循环
            def _do_tar_compress():
                """在线程中执行tar压缩操作，带进度跟踪"""
                if compression_enabled:
                    # 使用tar.gz，直接写入磁带盘符
                    tar_file = backup_dir / f"backup_{backup_set.set_id}_{timestamp}.tar.gz"
                    compresslevel = max(1, min(9, compression_level))
                    
                    with tarfile.open(tar_file, 'w:gz', compresslevel=compresslevel) as tar_archive:
```

**关键代码**:
- 使用 `tarfile.open(tar_file, 'w:gz', compresslevel=compresslevel)` 创建 tar.gz 压缩文件
- 未使用 `py7zr.SevenZipFile` 进行 7z 压缩
- 未读取 `self.settings.COMPRESSION_THREADS` 配置

4. **py7zr 导入但未使用**

虽然代码中导入了 `py7zr`：

```18:18:backup/backup_engine.py
import py7zr
```

但在压缩逻辑中并未实际使用。`mcp/core.py` 中的 `SevenZipCompressionHandler` 也只是一个占位实现：

```258:279:mcp/core.py
class SevenZipCompressionHandler(CompressionHandler):
    """7-Zip压缩处理器"""

    async def compress(self, data: bytes, level: int = 9) -> bytes:
        """使用7-Zip压缩数据"""
        try:
            import py7zr
            # 这里应该实现实际的7-Zip压缩逻辑
            return data  # 暂时返回原数据
        except Exception as e:
            logger.error(f"7-Zip压缩失败: {str(e)}")
            raise

    async def decompress(self, compressed_data: bytes) -> bytes:
        """使用7-Zip解压数据"""
        try:
            import py7zr
            # 这里应该实现实际的7-Zip解压逻辑
            return compressed_data  # 暂时返回原数据
        except Exception as e:
            logger.error(f"7-Zip解压失败: {str(e)}")
            raise
```

#### 启用7z多线程压缩的方法

如果需要启用 7z 多线程压缩，需要修改 `backup/backup_engine.py` 中的 `_compress_file_group()` 方法：

1. **使用 py7zr.SevenZipFile 替代 tarfile**
2. **在创建压缩文件时传入 threads 参数**：
   ```python
   with py7zr.SevenZipFile(
       archive_path, 
       mode='w',
       filters=[{'id': py7zr.FILTER_LZMA2}],
       threads=self.settings.COMPRESSION_THREADS  # 使用配置的线程数
   ) as archive:
       # 添加文件到压缩包
   ```

3. **读取 COMPRESSION_THREADS 配置**：
   ```python
   compression_threads = self.settings.COMPRESSION_THREADS
   ```

#### 当前压缩方式说明

**当前使用的压缩方式**: `tar.gz` (gzip压缩)

**特点**:
- 使用 Python 标准库 `tarfile`，无需额外依赖
- 压缩级别通过 `COMPRESSION_LEVEL` 配置（默认9）
- 不支持多线程压缩（gzip本身是单线程的）
- 压缩速度较快，但压缩率不如 7z

**配置项使用情况**:
- ✅ `COMPRESSION_LEVEL`: 已使用（控制 gzip 压缩级别）
- ❌ `COMPRESSION_THREADS`: 未使用（7z压缩未启用）
- ✅ `MAX_FILE_SIZE`: 已使用（控制单个压缩包大小限制）

## 相关文件

- `utils/scheduler/scheduler.py` - 调度器主类
- `utils/scheduler/task_executor.py` - 任务执行器
- `utils/scheduler/action_handlers.py` - 动作处理器
- `backup/backup_engine.py` - 备份引擎
- `config/settings.py` - 系统配置（包含压缩配置）
- `mcp/core.py` - 压缩处理器定义
- `docs/scheduled_task_execution_details.md` - 计划任务执行细节文档

## 总结

计划任务的执行流程是一个完整的异步处理链路，从调度器检测到任务执行完成，涉及多个组件的协作：

1. **调度器循环**：定期检查任务是否需要执行
2. **任务执行器**：管理任务执行的生命周期，包括锁管理、状态更新、日志记录
3. **动作处理器**：执行前检查、创建备份任务、格式化处理
4. **备份引擎**：实际执行备份操作

整个流程采用了完善的错误处理、并发控制和日志记录机制，确保任务执行的可靠性和可追溯性。

