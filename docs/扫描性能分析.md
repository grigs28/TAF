# 扫描性能分析

## 当前扫描速度
- **平均速度**: 112.1 个文件/秒
- **最近速度**: 110.8 个文件/秒（最近 4000 个文件用时 36.1 秒）

## 扫描过程做了什么

### 1. 文件系统遍历（后台线程）
- 使用 `os.scandir()` 遍历目录树
- 在独立的后台线程中执行，不阻塞主线程
- 将文件路径放入队列，分批提交（每批 300-1000 个路径，根据目录数量动态调整）

### 2. 路径处理（主线程）
- **路径字符串化**: `str(entry_path)` - 每个路径都要转换为字符串
- **路径长度检查**: 检查路径是否超过 Windows 限制（260 字符）
- **路径格式化**: 用于日志显示（截断过长路径）

### 3. 排除规则检查（主线程）
- **`should_exclude_file()`**: 对每个文件/目录都要检查
  - 标准化路径（替换反斜杠）
  - 检查路径本身是否匹配排除规则（遍历所有排除模式）
  - 检查所有父目录路径是否匹配排除规则（嵌套循环）
  - **复杂度**: O(n*m)，其中 n=路径深度，m=排除规则数量
  - **性能影响**: 如果排除规则很多，会有显著性能开销

### 4. 文件信息获取（主线程）
- **`get_file_info()`**: 对每个文件调用
  - `file_path.stat()` - **同步 I/O 操作**，获取文件大小、修改时间等信息
  - 创建文件信息字典（路径、名称、大小、时间戳等）
  - **性能影响**: `stat()` 调用是同步的，在 Windows 上可能较慢，特别是网络路径或慢速磁盘

### 5. 数据库写入（异步）
- **内存数据库写入器**（如果启用）:
  - 将文件信息写入内存 SQLite 数据库（极速）
  - 定期同步到 openGauss（每 30 秒或每 5000 个文件）
- **批量写入器**（如果未启用内存数据库）:
  - 将文件信息放入队列
  - 后台 worker 批量写入数据库

### 6. 进度更新（异步）
- 每 500 个文件更新一次数据库中的 `total_files` 和 `total_bytes`
- 每 60 秒输出一次统计日志

## 性能瓶颈分析

### 主要瓶颈

1. **`stat()` 调用（最大瓶颈）**
   - 每个文件都要调用 `file_path.stat()` 获取文件大小
   - 这是同步 I/O 操作，在 Windows 上可能较慢
   - 对于网络路径或慢速磁盘，延迟会更高
   - **优化建议**: 
     - 使用 `os.scandir()` 的 `stat()` 方法（如果可用）
     - 或者使用 `entry.stat()` 而不是 `Path.stat()`（`os.scandir()` 已经缓存了 stat 信息）

2. **排除规则检查**
   - `should_exclude_file()` 对每个文件都要检查所有排除规则
   - 如果排除规则很多，会有 O(n*m) 的复杂度
   - **优化建议**:
     - 缓存排除规则匹配结果（如果父目录已排除，子目录也排除）
     - 使用更高效的匹配算法（如前缀树）

3. **路径字符串化**
   - 每个路径都要转换为字符串
   - 路径长度检查
   - **优化建议**: 延迟字符串化，只在需要时转换

### 次要瓶颈

4. **数据库写入**
   - 虽然使用了内存数据库，但仍有开销
   - 定期同步到 openGauss 会有延迟

5. **进度更新**
   - 每 500 个文件更新一次数据库
   - 数据库更新是异步的，但仍有开销

## 优化建议

### 短期优化（快速实施）

1. **使用 `entry.stat()` 替代 `Path.stat()`**
   - `os.scandir()` 的 `entry` 对象已经缓存了 stat 信息
   - 直接使用 `entry.stat()` 可以避免额外的系统调用
   - **预期提升**: 20-30%

2. **优化排除规则检查**
   - 缓存已排除的目录（如果父目录已排除，子目录也排除）
   - 提前退出循环（如果找到匹配，立即返回）
   - **预期提升**: 10-20%（取决于排除规则数量）

3. **减少路径字符串化**
   - 延迟字符串化，只在需要时转换
   - 缓存字符串化的路径
   - **预期提升**: 5-10%

### 长期优化（需要重构）

1. **并行文件信息获取**
   - 使用线程池并行获取文件信息
   - 批量处理文件 stat 调用

2. **优化排除规则匹配**
   - 使用前缀树（Trie）存储排除规则
   - 实现更高效的匹配算法

3. **减少数据库写入频率**
   - 增加批量写入的大小
   - 减少进度更新的频率

## 当前性能对比

- **当前速度**: 112.1 个文件/秒
- **目标速度**: 1000+ 个文件/秒（用户期望）
- **性能差距**: 约 9 倍

## 结论

扫描速度慢的主要原因是：
1. **`stat()` 调用**：每个文件都要调用同步 I/O 操作获取文件大小
2. **排除规则检查**：对每个文件都要检查所有排除规则
3. **路径处理**：每个路径都要字符串化和长度检查

**最有效的优化**是使用 `entry.stat()` 替代 `Path.stat()`，可以避免额外的系统调用，预期可以提升 20-30% 的性能。

